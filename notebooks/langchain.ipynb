{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source: https://langchain.readthedocs.io/en/latest/modules/document_loaders/examples/pdf.html#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install faiss-cpu pymupdf chromadb -q\n",
    "\n",
    "# %pip install \"unstructured[local-inference]\" -q\n",
    "# %pip install \"detectron2@git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2\" -q\n",
    "# %brew install poppler\n",
    "# at the end, still had errors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pages 33\n",
      "page 1 \n",
      " Bayesian Data Analysis\n",
      "Module 3: Models with more than one parameter\n",
      "Stat 474/574\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"pdfs/09_The Normal (mu, sigma) model.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "print(\"pages\" , len(pages))\n",
    "print(\"page 1 \\n\", pages[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " page 25 \n",
      " Conjugate prior for the normal model (cont'd)\n",
      "Interpretation of posterior parameters:\n",
      "As before,\u0016nis a weighted average of the prior mean and the sample\n",
      "mean.\n",
      "The posterior \\guess\" \u0017n\u001b2\n",
      "nis the sum of the sample sum of squared\n",
      "deviations, the prior sum of squared deviations, and additional\n",
      "uncertainty due to the di\u000berence between the sample mean and the\n",
      "prior mean.\n",
      "Stat 474/574 (ISU) Spring, 2023 26 / 33\n",
      "\n",
      " page 21 \n",
      " Conjugate prior for the normal model\n",
      "Recall that using a non-informative prior, we found that\n",
      "p(\u0016j\u001b2;y)/N(\u0016y;\u001b2=n)\n",
      "p(\u001b2jy)/Inv\u0000\u001f2(n\u00001;s2):\n",
      "Then, factoring p(\u0016;\u001b2) =p(\u0016j\u001b2)p(\u001b2) the conjugate prior for \u001b2\n",
      "would also be scaled inverse \u001f2and for\u0016(conditional on \u001b2) would\n",
      "be normal.\n",
      "Stat 474/574 (ISU) Spring, 2023 22 / 33\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "faiss_index = FAISS.from_documents(pages, OpenAIEmbeddings())\n",
    "docs = faiss_index.similarity_search(\"What is conjugate prior for mean?\", k=2)\n",
    "for doc in docs:\n",
    "    print(f\"\\n page {str(doc.metadata['page'])} \\n {doc.page_content}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjugate prior for the normal model (cont’d)\n",
      "Interpretation of posterior parameters:\n",
      "As before, µn is a weighted average of the prior mean and the sample\n",
      "mean.\n",
      "The posterior “guess” νnσ2\n",
      "n is the sum of the sample sum of squared\n",
      "deviations, the prior sum of squared deviations, and additional\n",
      "uncertainty due to the diﬀerence between the sample mean and the\n",
      "prior mean.\n",
      "Stat 474/574 (ISU)\n",
      "Spring, 2023\n",
      "26 / 33\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "loader = PyMuPDFLoader(\"pdfs/09_The Normal (mu, sigma) model.pdf\")\n",
    "\n",
    "data = loader.load()\n",
    "data[0]\n",
    "\n",
    "print(data[25].page_content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VectorDB QA\n",
    "\n",
    "https://langchain.readthedocs.io/en/latest/modules/chat/examples/vector_db_qa_with_sources.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "loader = PyMuPDFLoader(\"pdfs/09_The Normal (mu, sigma) model.pdf\")\n",
    "\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Chroma using direct local API.\n",
      "Using DuckDB in-memory for database. Data will be transient.\n"
     ]
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "documents = text_splitter.split_documents(documents)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "docsearch = Chroma.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "\n",
    "system_template=\"\"\"Use the following pieces of context to answer the users question. \n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "----------------\n",
    "{context}\"\"\"\n",
    "messages = [\n",
    "    SystemMessagePromptTemplate.from_template(system_template),\n",
    "    HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "]\n",
    "prompt = ChatPromptTemplate.from_messages(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import VectorDBQA\n",
    "\n",
    "chain_type_kwargs = {\"prompt\": prompt}\n",
    "qa = VectorDBQA.from_chain_type(llm=ChatOpenAI(), chain_type=\"stuff\", vectorstore=docsearch, chain_type_kwargs=chain_type_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = qa.run(\"what is joint posterior distribution, conditional posterior, and marginal posterior of normal? Provide the notations and an english translation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The joint posterior distribution of normal in this context is denoted as p(µ, σ2|y), which represents the probability\n",
      "distribution of the two parameters (mean and variance) after observing the data y. This distribution can be obtained by\n",
      "multiplying the prior distribution of the two parameters with the likelihood function of the data, and is used to make\n",
      "inference about both parameters simultaneously.  The conditional posterior of normal, specifically of the mean parameter\n",
      "µ given the variance parameter σ2 and the data y, is denoted as µ|σ2, y. This represents the probability distribution of\n",
      "the mean parameter after observing the data y, conditional on the value of the variance parameter σ2. This distribution\n",
      "can be obtained from the joint posterior by using Bayes' theorem and isolating the mean parameter as the variable of\n",
      "interest.  The marginal posterior of normal is denoted as p(θ1|y), and represents the probability distribution of the\n",
      "variable of interest (in this case, the mean parameter) after observing the data y, marginalizing over the other\n",
      "parameter(s) (in this case, the variance parameter). This distribution can be obtained by integrating the joint\n",
      "posterior distribution over the nuisance parameter, resulting in a probability distribution that only involves the\n",
      "variable of interest.\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# wrap text in python\n",
    "import textwrap\n",
    "\n",
    "def wrap_text(text, width=120):\n",
    "    return \"\\n\".join(textwrap.wrap(text, width=width))\n",
    "\n",
    "print(wrap_text(res))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multiple documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "pdfs = os.listdir(\"pdfs\")\n",
    "loaders = []\n",
    "for pdf in pdfs:\n",
    "    loaders.append(PyMuPDFLoader(f\"pdfs/{pdf}\"))\n",
    "\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
